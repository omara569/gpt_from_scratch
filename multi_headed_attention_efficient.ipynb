{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to better understand the tensor method of multi-headed attention such that concatenating the results of each head is no longer necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, we will use 3 batches, 5 tokens per batch, 4 dimensional embeddings, and 2 attention heads\n",
    "batch, toks, num_embed, num_heads = 3, 5, 4, 2\n",
    "embeds_per_head = num_embed // num_heads\n",
    "\n",
    "X = torch.randn(batch, toks, num_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4107,  0.3778,  0.7939, -0.6678],\n",
       "         [ 1.0667, -0.6242,  0.1589,  0.3039],\n",
       "         [-0.2674, -0.1341,  0.4748,  0.1322],\n",
       "         [ 0.6318, -0.0575, -1.3057, -1.2878],\n",
       "         [ 0.1779, -0.0569, -0.2827,  0.2198]],\n",
       "\n",
       "        [[-0.7141,  1.9954, -1.2001, -1.6837],\n",
       "         [-1.6832,  0.7826, -0.9433,  0.8802],\n",
       "         [-0.1342, -0.0999, -0.8499, -0.0073],\n",
       "         [ 0.1937, -0.8343,  0.2319,  1.2950],\n",
       "         [-0.0885, -1.2308, -0.2638,  1.3568]],\n",
       "\n",
       "        [[-0.7015, -0.8345, -0.1715, -1.6207],\n",
       "         [ 1.0907, -0.6023, -0.2791,  1.2498],\n",
       "         [ 0.3522, -0.3134,  0.2640,  0.5063],\n",
       "         [-1.3687, -1.8509, -0.8862, -0.4323],\n",
       "         [ 0.7272, -0.2031, -0.4499,  0.4885]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the weight matrices\n",
    "Recall that in multi-headed attention, if we had 3x5x4 with two heads, we'd pass in 3x5x2 for each head.  \n",
    "Since we're just using entire square matrices instead of size num_embed, that means that the first two columns of our weights represents our first head and the second two columns represent our second head for Q, K, and V respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.4780, -0.9516,  0.4366, -2.9062],\n",
       "         [-0.1026, -0.4280, -1.3834,  1.7105],\n",
       "         [ 1.1762, -0.0482,  0.2124,  0.4522],\n",
       "         [-1.3839,  0.0114,  1.0256,  1.1996]]),\n",
       " tensor([[-1.3381, -0.4638, -0.3170, -0.2636],\n",
       "         [-0.0936,  0.3665,  0.6969, -2.0485],\n",
       "         [ 1.0330, -0.0390,  0.6749,  0.5791],\n",
       "         [-0.8078, -0.1961,  1.3025,  0.3515]]),\n",
       " tensor([[-0.8592,  0.3266, -0.4633, -0.3311],\n",
       "         [-0.5480, -1.2023,  0.2072, -0.6125],\n",
       "         [-0.3491, -0.8961, -0.2169,  2.0952],\n",
       "         [ 0.4727,  1.8188,  0.0249, -0.8341]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "W_query, W_key, W_val = torch.randn(4, 4), torch.randn(4, 4), torch.randn(4, 4)\n",
    "W_query, W_key, W_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 4]),\n",
       " torch.Size([3, 5, 4]),\n",
       " torch.Size([3, 5, 4]),\n",
       " tensor([[[ 2.4263,  0.1833, -1.2183,  1.3977],\n",
       "          [-1.7461, -0.7521,  1.6746, -3.7312],\n",
       "          [ 0.7845,  0.2905,  0.3053,  0.9209],\n",
       "          [-0.6815, -0.5284, -1.2427, -4.0697],\n",
       "          [-0.8939, -0.1288,  0.3218, -0.4786]],\n",
       " \n",
       "         [[ 1.7692, -0.1359, -5.0540,  2.9260],\n",
       "          [ 0.0800,  1.3224, -1.1150,  6.8596],\n",
       "          [-0.7809,  0.2113, -0.1084, -0.1740],\n",
       "          [-1.7200,  0.1764,  2.6162, -0.3316],\n",
       "          [-1.9308,  0.6392,  2.9996, -0.3397]],\n",
       " \n",
       "         [[ 3.1636,  1.0145, -0.8505, -1.4105],\n",
       "          [-3.6081, -0.7524,  2.5320, -2.8268],\n",
       "          [-0.8785, -0.2079,  1.1627, -0.8327],\n",
       "          [ 1.7688,  2.1324,  1.3316, -0.1077],\n",
       "          [-2.2591, -0.5778,  1.0038, -2.0781]]]),\n",
       " tensor([[[ 1.8739e+00,  4.2898e-01,  5.9448e-02, -4.4064e-01],\n",
       "          [-1.4501e+00, -7.8936e-01, -2.7011e-01,  1.1963e+00],\n",
       "          [ 7.5407e-01,  3.0389e-02,  4.8396e-01,  6.6672e-01],\n",
       "          [-1.1485e+00, -1.0583e-02, -2.7990e+00, -1.2574e+00],\n",
       "          [-7.0244e-01, -1.3548e-01, -5.7578e-04, -1.6771e-02]],\n",
       " \n",
       "         [[ 8.8912e-01,  1.4397e+00, -1.3860e+00, -5.1861e+00],\n",
       "          [ 4.9355e-01,  9.3177e-01,  1.5888e+00, -1.3962e+00],\n",
       "          [-6.8313e-01,  6.0223e-02, -6.1023e-01, -2.5468e-01],\n",
       "          [-9.8767e-01, -6.5868e-01,  1.2004e+00,  2.2475e+00],\n",
       "          [-1.1349e+00, -6.6590e-01,  7.5959e-01,  2.8687e+00]],\n",
       " \n",
       "         [[ 2.1489e+00,  3.4406e-01, -2.5860e+00,  1.2255e+00],\n",
       "          [-2.7010e+00, -9.6089e-01,  6.7406e-01,  1.2239e+00],\n",
       "          [-5.7817e-01, -3.8784e-01,  5.0765e-01,  8.8004e-01],\n",
       "          [ 1.4385e+00,  7.5768e-02, -2.0173e+00,  3.4874e+00],\n",
       "          [-1.8134e+00, -4.8996e-01, -3.9444e-02,  1.3539e-01]]]),\n",
       " tensor([[[-4.4702e-01, -2.5145e+00,  7.9683e-02,  2.1250e+00],\n",
       "          [-4.8626e-01,  1.5091e+00, -6.5040e-01,  1.0873e-01],\n",
       "          [ 1.9994e-01, -1.1114e-01, -3.6364e-03,  1.0553e+00],\n",
       "          [-6.6414e-01, -8.9663e-01, -5.3438e-02, -1.8354e+00],\n",
       "          [ 8.0949e-02,  7.7976e-01, -2.7410e-02, -7.9982e-01]],\n",
       " \n",
       "         [[-8.5678e-01, -4.6191e+00,  9.6263e-01, -2.0958e+00],\n",
       "          [ 1.7628e+00,  9.5554e-01,  1.1685e+00, -2.6327e+00],\n",
       "          [ 4.6331e-01,  8.2457e-01,  2.2565e-01, -1.6689e+00],\n",
       "          [ 8.2201e-01,  3.2139e+00, -2.8060e-01, -1.4751e-01],\n",
       "          [ 1.4839e+00,  4.1549e+00, -1.2296e-01, -9.0127e-01]],\n",
       " \n",
       "         [[ 3.5382e-01, -2.0199e+00,  1.4893e-01,  1.7359e+00],\n",
       "          [ 8.1186e-02,  3.6036e+00, -5.3838e-01, -1.6194e+00],\n",
       "          [ 1.6326e-02,  1.1761e+00, -2.7274e-01,  2.0622e-01],\n",
       "          [ 2.2954e+00,  1.7861e+00,  4.3209e-01,  9.0799e-02],\n",
       "          [-1.2554e-01,  1.7732e+00, -2.6918e-01, -1.4665e+00]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we perform the multiplications to get our Q, K, and V. Again, the first two rows represent our result for the first head and second two for the second in Q, K, and V respectively\n",
    "Q, K, V = X@W_query, X@W_key, X@W_val\n",
    "Q.shape, K.shape, V.shape, Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.4263,  0.1833, -1.2183,  1.3977],\n",
       "          [-1.7461, -0.7521,  1.6746, -3.7312],\n",
       "          [ 0.7845,  0.2905,  0.3053,  0.9209],\n",
       "          [-0.6815, -0.5284, -1.2427, -4.0697],\n",
       "          [-0.8939, -0.1288,  0.3218, -0.4786]],\n",
       " \n",
       "         [[ 1.7692, -0.1359, -5.0540,  2.9260],\n",
       "          [ 0.0800,  1.3224, -1.1150,  6.8596],\n",
       "          [-0.7809,  0.2113, -0.1084, -0.1740],\n",
       "          [-1.7200,  0.1764,  2.6162, -0.3316],\n",
       "          [-1.9308,  0.6392,  2.9996, -0.3397]],\n",
       " \n",
       "         [[ 3.1636,  1.0145, -0.8505, -1.4105],\n",
       "          [-3.6081, -0.7524,  2.5320, -2.8268],\n",
       "          [-0.8785, -0.2079,  1.1627, -0.8327],\n",
       "          [ 1.7688,  2.1324,  1.3316, -0.1077],\n",
       "          [-2.2591, -0.5778,  1.0038, -2.0781]]]),\n",
       " tensor([[[[ 2.4263,  0.1833],\n",
       "           [-1.2183,  1.3977]],\n",
       " \n",
       "          [[-1.7461, -0.7521],\n",
       "           [ 1.6746, -3.7312]],\n",
       " \n",
       "          [[ 0.7845,  0.2905],\n",
       "           [ 0.3053,  0.9209]],\n",
       " \n",
       "          [[-0.6815, -0.5284],\n",
       "           [-1.2427, -4.0697]],\n",
       " \n",
       "          [[-0.8939, -0.1288],\n",
       "           [ 0.3218, -0.4786]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7692, -0.1359],\n",
       "           [-5.0540,  2.9260]],\n",
       " \n",
       "          [[ 0.0800,  1.3224],\n",
       "           [-1.1150,  6.8596]],\n",
       " \n",
       "          [[-0.7809,  0.2113],\n",
       "           [-0.1084, -0.1740]],\n",
       " \n",
       "          [[-1.7200,  0.1764],\n",
       "           [ 2.6162, -0.3316]],\n",
       " \n",
       "          [[-1.9308,  0.6392],\n",
       "           [ 2.9996, -0.3397]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1636,  1.0145],\n",
       "           [-0.8505, -1.4105]],\n",
       " \n",
       "          [[-3.6081, -0.7524],\n",
       "           [ 2.5320, -2.8268]],\n",
       " \n",
       "          [[-0.8785, -0.2079],\n",
       "           [ 1.1627, -0.8327]],\n",
       " \n",
       "          [[ 1.7688,  2.1324],\n",
       "           [ 1.3316, -0.1077]],\n",
       " \n",
       "          [[-2.2591, -0.5778],\n",
       "           [ 1.0038, -2.0781]]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to slice on the head. For each head, we want to perform the calculations for the tokens - but first we need to reshape to split the heads from one another\n",
    "Q_reshaped, K_reshaped, V_reshaped = Q.reshape((batch, toks, num_heads, embeds_per_head)), K.reshape((batch, toks, num_heads, embeds_per_head)), V.reshape((batch, toks, num_heads, embeds_per_head))\n",
    "Q, Q_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 5, 2]),\n",
       " tensor([[[[ 2.4263,  0.1833],\n",
       "           [-1.7461, -0.7521],\n",
       "           [ 0.7845,  0.2905],\n",
       "           [-0.6815, -0.5284],\n",
       "           [-0.8939, -0.1288]],\n",
       " \n",
       "          [[-1.2183,  1.3977],\n",
       "           [ 1.6746, -3.7312],\n",
       "           [ 0.3053,  0.9209],\n",
       "           [-1.2427, -4.0697],\n",
       "           [ 0.3218, -0.4786]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7692, -0.1359],\n",
       "           [ 0.0800,  1.3224],\n",
       "           [-0.7809,  0.2113],\n",
       "           [-1.7200,  0.1764],\n",
       "           [-1.9308,  0.6392]],\n",
       " \n",
       "          [[-5.0540,  2.9260],\n",
       "           [-1.1150,  6.8596],\n",
       "           [-0.1084, -0.1740],\n",
       "           [ 2.6162, -0.3316],\n",
       "           [ 2.9996, -0.3397]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1636,  1.0145],\n",
       "           [-3.6081, -0.7524],\n",
       "           [-0.8785, -0.2079],\n",
       "           [ 1.7688,  2.1324],\n",
       "           [-2.2591, -0.5778]],\n",
       " \n",
       "          [[-0.8505, -1.4105],\n",
       "           [ 2.5320, -2.8268],\n",
       "           [ 1.1627, -0.8327],\n",
       "           [ 1.3316, -0.1077],\n",
       "           [ 1.0038, -2.0781]]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we have to reorder these matrices so that the next operation we perform is on each head (i.e. Each head's tokens within each batch)\n",
    "Q_transposed, K_transposed, V_transposed = Q_reshaped.transpose(1, 2), K_reshaped.transpose(1,2), V_reshaped.transpose(1,2)\n",
    "Q_transposed.shape, Q_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can perform the mutliplications of Q, K, and V\n",
    "attention_scores = Q_transposed.matmul(K_transposed.transpose(-1, -2)) / torch.sqrt(torch.tensor(embeds_per_head))\n",
    "attention_weights = attention_scores.softmax(-1)\n",
    "attention_output = attention_weights.matmul(V_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 5, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = attention_output.transpose(1, 2).reshape((batch, toks, num_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3653, -2.1769, -0.2775, -0.3521],\n",
       "         [-0.4260,  0.7236,  0.0292,  0.8496],\n",
       "         [-0.2518, -1.1838, -0.2297,  0.4191],\n",
       "         [-0.3408,  0.3906, -0.0524, -1.8018],\n",
       "         [-0.3533,  0.3619, -0.0861,  0.2703]],\n",
       "\n",
       "        [[ 0.2911, -1.5369, -0.0725, -0.9939],\n",
       "         [ 0.2940, -1.3769, -0.1282, -0.8760],\n",
       "         [ 0.8445,  1.6671,  0.5764, -1.7316],\n",
       "         [ 0.9703,  2.5523,  0.8498, -2.1205],\n",
       "         [ 0.9332,  2.3235,  0.8879, -2.1783]],\n",
       "\n",
       "        [[ 0.6329, -1.4681, -0.0613,  0.2982],\n",
       "         [ 0.0656,  3.4597, -0.3245, -0.9952],\n",
       "         [ 0.0967,  2.5831, -0.3388, -0.8774],\n",
       "         [ 0.7639, -1.1742, -0.3501, -0.8506],\n",
       "         [ 0.0478,  3.2505, -0.3105, -0.9926]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
